{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71c6e3d9-bfb8-4d63-af0d-cd4e9acb0df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: XLA_PYTHON_CLIENT_ALLOCATOR=platform\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env XLA_PYTHON_CLIENT_ALLOCATOR=platform\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import chex\n",
    "import jax\n",
    "import flax\n",
    "import torch\n",
    "import optax\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn\n",
    "from einops import rearrange\n",
    "from flax.training import train_state, checkpoints\n",
    "\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.datasets import GNNBenchmarkDataset, TUDataset, ZINC\n",
    "\n",
    "import sys\n",
    "path = '../'\n",
    "sys.path.append(path)\n",
    "from src import get_nparams, get_graph, to_device_split, init_model, train_loop, eval_nfold, eval_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87c3482d-93a3-4f6a-a623-f87e17514cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "from functools import partial\n",
    "import jax.experimental.sparse as jsparse\n",
    "\n",
    "@jax.vmap\n",
    "def l1_loss(preds: jnp.ndarray, targets: jnp.ndarray):\n",
    "    chex.assert_equal_shape((preds, targets))\n",
    "    return jnp.abs(preds - targets).mean()\n",
    "\n",
    "\n",
    "def compute_loss(\n",
    "    params,\n",
    "    data: dict,\n",
    "    apply_fn: Callable,\n",
    "    kclasses: int,\n",
    "    to_device: bool,\n",
    "    **kwargs\n",
    "):\n",
    "    \n",
    "    labels = data.pop('Y')\n",
    "    \n",
    "    # Make sure we are the correct logits for the current task (CLS vs Final X-representation)\n",
    "    results = apply_fn({'params': params}, data['X'], data['A'], data['P'], data['key'], False, True)\n",
    "    \n",
    "    logits = results['CLS']\n",
    "    loss = l1_loss(logits.squeeze(), labels).mean()\n",
    "    accuracy = jnp.array([1e-8]).mean()\n",
    "        \n",
    "    if to_device:\n",
    "        loss, accuracy = map(lambda x : jax.lax.pmean(x, 'batch'), (loss, accuracy))\n",
    "        \n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65f10b9f-340e-440a-bb11-25226ce8658d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = data_name = 'ZINC'\n",
    "saved_dir = \"./saved_models/\" + model_name\n",
    "path = './stats/' + model_name + '_stats.npy'\n",
    "\n",
    "batch_size = 128 * 8\n",
    "\n",
    "train_data = ZINC(root = '../data/', split = 'train')\n",
    "test_data = ZINC(root = '../data/', split = 'test')\n",
    "valid_data = ZINC(root = '../data/', split = 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76e7860e-3c74-4e6f-9a31-8d00ed829152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PARAMS COUNT: 1052409\n"
     ]
    }
   ],
   "source": [
    "from src import GraphET\n",
    "\n",
    "k = 15                       # N x k pos_embedding dim we want to use (2 * k if we use svd)\n",
    "kclasses = 1                 # output dim\n",
    "embed_type = 'eigen'         # pos_embedding type\n",
    "task_level = 'graph'         # graph or node level \n",
    "to_device = True\n",
    "max_num_nodes = 500\n",
    "\n",
    "model = GraphET(\n",
    "    embed_dim = 128,\n",
    "    out_dim = kclasses, \n",
    "    nheads = 12,\n",
    "    alpha = 0.1,\n",
    "    depth = 1,\n",
    "    block = 4,\n",
    "    head_dim = 64,\n",
    "    multiplier = 4.,\n",
    "    dtype = jnp.float32,\n",
    "    kernel_size = [3, 3],\n",
    "    kernel_dilation = [1, 1],\n",
    "    compute_corr = True,\n",
    "    vary_noise = False,\n",
    "    chn_atype = 'relu',\n",
    ")\n",
    "\n",
    "key = jax.random.PRNGKey(42)\n",
    "\n",
    "params = init_model(\n",
    "    DataLoader(train_data, batch_size = 1), key, model, k, embed_type, task_level)\n",
    "\n",
    "print(\"PARAMS COUNT:\", get_nparams(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b3e1d0a-3a57-4c21-b8fd-407b719604d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2 ** 32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "key, _ = jax.random.split(key)\n",
    "g.manual_seed(3407 + int(jnp.mean(key)))\n",
    "\n",
    "train_loader, valid_loader, test_loader = map(\n",
    "    lambda x : DataLoader(x, shuffle = True, batch_size = batch_size, worker_init_fn = seed_worker, generator = g), \n",
    "    (train_data, valid_data, test_data)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59711e1f-94fa-41db-9570-0de83f38462c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "total_epochs = 500\n",
    "\n",
    "warmup_steps = 50 * len(train_loader) \n",
    "total_steps = len(train_loader) * total_epochs\n",
    "\n",
    "scheduler = optax.warmup_cosine_decay_schedule(\n",
    "    init_value = 5e-7,\n",
    "    peak_value = 1e-3,\n",
    "    warmup_steps = warmup_steps,\n",
    "    decay_steps = total_steps,\n",
    "    end_value = 5e-7,\n",
    ")\n",
    "\n",
    "optimizer = optax.chain(\n",
    "    optax.centralize(),\n",
    "    optax.adamw(\n",
    "        learning_rate = scheduler, \n",
    "        weight_decay=0.05,\n",
    "        b1=0.9,\n",
    "        b2=0.99,\n",
    "    ),\n",
    ")    \n",
    "\n",
    "state = train_state.TrainState.create(apply_fn = model.apply, params = params, tx = optimizer)\n",
    "state = checkpoints.restore_checkpoint(ckpt_dir = saved_dir, target = state)\n",
    "\n",
    "if to_device:\n",
    "    state = flax.jax_utils.replicate(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9de2a097-bb89-46da-b6c6-6a4a9bf6bb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_compute_loss = jax.pmap(\n",
    "    partial(compute_loss, to_device=to_device, kclasses=kclasses, apply_fn=state.apply_fn),\n",
    "    axis_name='batch',\n",
    "    in_axes=(0, {'X': 0, 'Y': 0, 'P': 0, 'A': 0, 'key': 0})\n",
    ")\n",
    "\n",
    "get_valid_data = partial(\n",
    "    get_graph, \n",
    "    max_num_nodes = max_num_nodes, \n",
    "    k = k, \n",
    "    embed_type = embed_type,\n",
    "    task_level = task_level,\n",
    "    to_device = to_device,\n",
    "    flip_sign = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e858668-2ca5-4518-b37a-a63e5901c766",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [04:49<00:00,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0964311063438654 ± 0.0004528819147532612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "L = []\n",
    "for _ in tqdm.tqdm(range(100)):\n",
    "    loss, _ = eval_loop(\n",
    "            state,\n",
    "            test_loader,\n",
    "            get_valid_data,\n",
    "            valid_compute_loss,\n",
    "            True\n",
    "    )\n",
    "    \n",
    "    L.append(loss)\n",
    "\n",
    "print(u\"Loss: {0} \\u00B1 {1}\".format(np.mean(L), np.std(L)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
